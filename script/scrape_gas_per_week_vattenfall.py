#!/usr/bin/env python
#
# Copyright 2023 by Martin Moene
#
# Distributed under the Boost Software License, Version 1.0.
# (See accompanying file LICENSE.txt or copy at http://www.boost.org/LICENSE_1_0.txt)
#
# Scrape given text file with Vattenfall per-week electricity usage for its entries and create a csv file of it.
#
# Usage: script/scrape_electricity_per_week_vattenfall.py [-h] [-v] [options...] file.txt
#
# Dependencies:
# - Python standard library.
#
# Process:
# 1. Handle command line options: output file, output folder, log level
# 2. Iterate over one or more files, folders, or wildcard-specified files
# 3. For each file, scrape its content, write out the CSV to a file (stdout for single file, and no --output option)
#
# Folders used:
# - Folders that are part of files to be read.
# - Command line specified --output: folder of path specified (if any) must exist.
# - Command line specified --csv-folder: must exists when specified.
#
# Output:
# - Fields separated by ';'.
# - Energy in Wh without ',' or '.'.
# - Money in €, using '.' as separator, such as '-2.15' (optionally as '€ -2.15', see to_money()).
#

from __future__ import print_function

import re
import os
import sys
import argparse
import calendar

EXIT_SUCCESS = 0
EXIT_FAILURE = 1

LOG_FILENAME  = 1
LOG_PROCESSED = 2
LOG_PROGRESS  = 3

# Line information of text file copy-pasted from Vattenfal web page with a month's electricity usage per week:
line_year         = 27      # Note: per 11-May-2023
line_week_first   = 35      # Note: per 11-May-2023
line_week_current = line_week_first
line_week_count    = (7, 14) # Note: changes with presence of teruglevering

# Day entry information:
with_teruglevering        = False
text_teruglevering        = 'Teruglevering'
offset_teruglevering_text = 4    # Note: used to probe for entry with 'Teruglevering'

# Offsets into a week's entry:
#      zonder teruglevering | met teruglevering
offset_datum           =  0
offset_levering        = (2 ,  2)
offset_teruglevering   =  5
offset_nettoverbruik   = (2 ,  9)
offset_vastekosten     = (6 , 13)
offset_variabelekosten = (3 , 10)
offset_totalekosten    = (0 ,  0)

# Vattenfall: Usage information for a single week to scrape from input file (at week_line(week)):
#
# A. Case without teruglevering:
# Ndx | Line contents     E | G                | Information
#  0  | 1 januari € 2,75    | 1 januari € 6,48 | [date] {Totale kosten}
#  1  | Variabele kosten    | .                |
#  2  | 8,838 kWh           | 3,16 M³          | {Levering}
#  3  | € 3,24              | € 5,63           | {Variable Kosten}
#  4  | Vaste kosten        | .                |
#  5  | 1 dg                | .                |
#  6  | € -0,49             | € 0,85           | {Vaste kosten}
#
# B. Case with teruglevering:
# Ndx | Line contents     E | Information
#  0  | 8 mei € -2,15       | [date] {Totale kosten}
#  1  | Stroom              |
#  2  | 3,985 kWh           | {Levering}
#  3  | -                   |
#  4  | Teruglevering       |
#  5  | -13,862 kWh         | {Teruglevering}
#  6  | -                   |
#  7  | Netto verbruik      |
#  8  | Variabele kosten    |
#  9  | -9,877 kWh          | {Netto Verbruik}
# 10  | € -1,66             | {Variabele kosten}
# 11  | Vaste kosten        |
# 12  | 1 dg                |
# 13  | € -0,49             | {Vaste kosten}
#
# https://www.vattenfall.nl/service/mijn-vattenfall/#/vf/verbruik
#

# Excel sheet table to create from reading csv file (note: '€' is displayed due to column format):
#
# Datum	Levering [M³/1000]	Teruglevering [M³/1000]	Netto Verbruik [M³/1000]	Vaste Kosten	Variable Kosten	Totale kosten
# TODO
# ...
# TODO
#

# CSV format generated by script:
#
# Datum;Levering [M³/1000];Teruglevering [M³/1000];Netto Verbruik [M³/1000];Vaste Kosten;Variable Kosten;Totale kosten
# 1-2022;43000;0;43000;5.28;34.82;40.10
# ...
# 52-2022;37000;0;37000;4.70;57.74;62.44
#

# Methods to scrape:
#
# A. Expect format with teruglevering only, iterate through days in month, scrape info from fixed lines.
# B. Scan for day in month, determine kind of entry, scrape info accordingly.
#
# Method B. is used in this script.
#

def log(level, cmdargs, *args, **kwargs):
    """Print a log message, depending on its verbosity level"""
    if cmdargs.verbose >= level:
        print(*args, file=sys.stderr, **kwargs)

def eprint(*args, **kwargs):
    """Print an error"""
    print(*args, file=sys.stderr, **kwargs)

def wprint(*args, **kwargs):
    """Print a warning"""
    print(*args, file=sys.stderr, **kwargs)

def is_wildcard(path):
    """True if path contains a wildcard"""
    return '*' in path or '?' in path

def plural(text, count):
    """Return plural of text if count larger than one"""
    return text + ('s' if count > 1 else '')

def reset():
    """Reset state for processing the next file"""
    global line_week_current
    line_week_current = line_week_first

# def probe_teruglevering(lines, week):
#     """Probe if currently selected week contains 'Terugleveren'."""
#     # eprint('Probe teruglevering: {}'.format(lines[week_index(week) + offset_teruglevering_text]))
#     return text_teruglevering in lines[week_index(week) + offset_teruglevering_text]

# def determine_if_week_with_teruglevering(lines, week):
#     """Determine if currently selected week contains 'Terugleveren', sets or resets flag accordingly."""
#     global with_teruglevering
#     with_teruglevering = probe_teruglevering(lines, week)
#     return with_teruglevering

def advance_week():
    """Advance 'line with current week' to next week, taking presence or absence of 'Terugleveren' into account."""
    global line_week_current
    line_week_current = line_week_current + line_week_count[with_teruglevering]

def week_line(week):
    """Number of line with date for currently active week."""
    return line_week_current

def week_index(week):
    """Index into file content with date for currently active week."""
    return week_line(week) - 1

# def days_in_month(year, month):
#     """Number of days in given month and year."""
#     return calendar.monthrange(year, month)[1]

def year_index():
    """Index into file content for line with month."""
    return line_year - 1

def scrape_year(lines):
    """Scrape year, return as numbers (year, weeks), TODO: weeks fixed at 52."""
    # eprint(lines[year_index()].split())
    year = lines[year_index()]
    return int(year), 52

def scrape_week_datum(lines, week):
    """Just return given week number."""
    return week

def to_date(year, week):
    """Return date as 'wk-yyyy'."""
    return '{week}-{year}'.format(week=week, year=year)

def to_M3(text):
    """Return number of M3/1000 as integer."""
    return round(1000 * float(text.split()[0].replace(',', '.')))

def to_money(text):
    """Return amount with ',' replaced by '.', like '-1.23'."""
    # money provided as '-' (empty) or '€ 1,23' (variabele, vaste kosten) or '1 mei € 1,23' (levering)
    zero = '0' # '€ 1,23'
    if text == '-':
        return zero
    import re
    # split on and keep '€ ', and take last two elements:
    result = re.split('(€ )', text)[-2:]
    return (result[1]).replace(',', '.') if len(result) > 1 else zero
    # return (result[0] + result[1]).replace(',', '.') if len(result) > 1 else zero

def scrape_week_levering(lines, week):
    """Scrape 'Levering' for a week."""
    return to_M3(lines[week_index(week) + offset_levering[with_teruglevering]])

def scrape_week_teruglevering(lines, week):
    """Scrape 'Teruglevering' for a week."""
    return to_M3(lines[week_index(week) + offset_teruglevering]) if with_teruglevering else 0

def scrape_week_nettoverbruik(lines, week):
    """Scrape 'Netto Verbruik' for a week."""
    return to_M3(lines[week_index(week) + offset_nettoverbruik[with_teruglevering]])

def scrape_week_vastekosten(lines, week):
    """Scrape 'Vaste Kosten' for a week."""
    return to_money(lines[week_index(week) + offset_vastekosten[with_teruglevering]])

def scrape_week_variabelekosten(lines, week):
    """Scrape 'Variabele Kosten' for a week."""
    return to_money(lines[week_index(week) + offset_variabelekosten[with_teruglevering]])

def scrape_week_totalelekosten(lines, week):
    """Scrape 'Totale Kosten' for a week."""
    return to_money(lines[week_index(week) + offset_totalekosten[with_teruglevering]])

def scrape_week(lines, week, year):
    """Scrape information for a single week."""
    # determine_if_week_with_teruglevering(lines, week)
    # eprint('with_teruglevering:{}'.format(with_teruglevering))
    return (
        to_date(year, week),
        scrape_week_levering(lines, week),
        scrape_week_teruglevering(lines, week),
        scrape_week_nettoverbruik(lines, week),
        scrape_week_vastekosten(lines, week),
        scrape_week_variabelekosten(lines, week),
        scrape_week_totalelekosten(lines, week),
    )

def scrape(src, args):
    """Scrape usage information from text file '{}'."""
    log(LOG_PROGRESS, args, scrape.__doc__.format(src))
    log(LOG_FILENAME, args, src)

    reset()

    import codecs
    with codecs.open(src, "r", "utf-8", errors='surrogateescape') as input:
        # read lines without newlines:
        lines = input.read().splitlines()

    year, weeks = scrape_year(lines)
    log(LOG_PROGRESS, args, 'year:{} weeks:{}'.format(year, weeks))

    result = []
    for week in range(1, weeks + 1):
        # eprint('Week: {}'.format(lines[week_index(week)]))
        result.append(scrape_week(lines, week, year))
        advance_week()

    return result

def report_header(args, output):
    """Report header."""
    log(LOG_PROGRESS, args, report_header.__doc__)
    print("Datum;Levering [M³/1000];Teruglevering [M³/1000];Netto Verbruik [M³/1000];Vaste Kosten;Variable Kosten;Totale kosten", file=output)

def report_entries(args, data, output):
    """Report entries."""
    log(LOG_PROGRESS, args, report_entries.__doc__)
    for entry in data:
        # eprint(entry)
        print('{date};{levering};{terug};{netto};{vast};{variabel};{totaal}'.format(
            date=entry[0], levering=entry[1], terug=entry[2], netto=entry[3],
            vast=entry[4], variabel=entry[5], totaal=entry[6]), file=output)

def report(args, data, output):
    """Report header and week entries, return 1 (processed one file)."""
    log(LOG_PROGRESS, args, report.__doc__.format(args.paths[0]))
    report_header(args, output)
    report_entries(args, data, output)
    return 1

def to_extension(path, ext):
    """Return path with extension replaced by ext."""
    return os.path.splitext(path)[0] + ext

def to_output_path(args, path):
    """Generate path for CSV output file based taking output folder from option '--csv-folder' into account"""
    # Two cases, depending on whether output folder is specified on command line:
    # - is not specified: replace extension '.txt'. with '.csv;
    # - is specified: replace extension '.txt'. with '.csv and replace folder with provided one.
    if args.csv_folder:
        return os.path.join(args.csv_folder, to_extension(os.path.basename(path), '.csv'))
    else:
        return to_extension(path, '.csv')

def scrape_and_report_file(path, args, output):
    """Scrape text in specified file and create csv files of it; honours option -o, --output"""
    if os.path.isfile(path):
        return report(args, scrape(path, args), output)
    else:
        return 0

def scrape_and_report_folder(folder, args):
    """Scrape text files in folder' and create csv files of them."""

    # TODO implement sanity checks
    # if not has_csv_folder(opts) then
    #     error("can only process folder when destination is specified via option '--csv-folder'.");
    # end if;

    # if folder = opts.csv_folder then
    #     error("folder to process must differ from folder specified with option '--csv-folder', both are: '" & To_String(folder) & "'.");
    # end if;

    count = 0
    for filename in os.listdir(folder):
        path = os.path.join(folder, filename)
        if os.path.isfile(path):
            log(LOG_PROGRESS, args, "Creating '{}'.".format(to_output_path(args, path)))
            with open(to_output_path(args, path), 'w') as output:
                count = count + report(args, scrape(path, args), output)
    return count

def scrape_and_report_wildcard(wildcard, args):
    """Scrape text files in folder' and create csv files of them."""
    import glob
    count = 0
    for path in glob.glob(wildcard):
        if os.path.isfile(path):
            log(LOG_PROGRESS, args, "Creating '{}'.".format(to_output_path(args, path)))
            with open(to_output_path(args, path), 'w') as output:
                count = count + report(args, scrape(path, args), output)
    return count

def scrape_and_report(args, output):
    """Scrape text file(s) '{}' and create csv file(s)."""
    log(LOG_PROGRESS, args, scrape_and_report.__doc__.format(args.paths[0]))
    count = 0
    try:
        for path in args.paths:
            if os.path.isfile(path):
                count = count + scrape_and_report_file(path, args, output)
            elif os.path.isdir(path):
                count = count + scrape_and_report_folder(path, args)
            elif not is_wildcard(path):
                wprint("Warning: file or folder '{}' not found.".format(path))
            else:
                count = count + scrape_and_report_wildcard(path, args)
    except OSError as err:
        eprint('Error: {}'.format(err))
    if count > 0:
        log(LOG_PROCESSED, args, '{count} {files} processed.'.format(count=count, files=plural('file', count)))
    else:
        wprint('Warning: not a single file processed.')

def option_output(args):
    """..."""
    return args.output

def has_paths(args):
    """..."""
    return len(args.paths) > 0

def multiple_files(args):
    """..."""
    return len(args.paths) > 1 or not os.path.isfile(args.paths[0])

def error(text, status):
    """..."""
    eprint('Error: {}'.format(text))
    return status

def main():
    """Scrape given text file(s) with Vattenfall daily electricity usage and create a csv file of it."""

    parser = argparse.ArgumentParser(
        description="""Scrape given text file(s) with Vattenfall daily electricity usage and create file(s) in csv format.
Single file output is to stdout default and can be directed to a file using option '--output'.
When multiple files are specified, output is to a file of the same name with the extension replaced with '.csv'.
Multiple file output can be directed to a folder using option '--csv-folder'.
""",
        epilog="""""",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
#        formatter_class=argparse.RawTextHelpFormatter)

    parser.add_argument(
        '-v', '--verbose',
        action='count',
        default=0,
        help='report file being processed (level 1), count (2), progress (3)')

    # parser.add_argument(
    #     '--input-folder',
    #     metavar='input',
    #     default=None,
    #     type=str,
    #     help='folder that contains source txt files')

    parser.add_argument(
        '--csv-folder',
        metavar='csv',
        default=None,
        type=str,
        help='folder to write csv files to')

    parser.add_argument(
        '--output',
        metavar='output',
        type=str,
        help='output file in csv format')

    parser.add_argument(
        'paths',
        metavar='paths',
        default='',
        type=str,
        nargs='+',
        help='file(s) with copy-pasted web page text (file, folder, wildcard)')

    args = parser.parse_args()

    # eprint(args)

    if option_output(args) and multiple_files(args):
        return error("can only use option '--output' with a single file.", EXIT_FAILURE)

    if has_paths(args):
        if option_output(args):
            with open(args.output, 'w') as output:
                scrape_and_report(args, output)
        else:
            scrape_and_report(args, sys.stdout)
    else:
        parser.print_help()

if __name__ == '__main__':
    main()

# end of file
